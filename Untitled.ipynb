{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": { },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelheydt/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/michaelheydt/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/warandpeace.html\")\n",
    "bsObj = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "nameList = bsObj.findAll(\"span\", {\"class\":\"green\"})\n",
    "for name in nameList:\n",
    "    print(name.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of librarian-related job positions that the federal government is currently hiring for\n",
    "import requests\n",
    "# via http://www.opm.gov/policy-data-oversight/classification-qualifications/general-schedule-qualification-standards/#url=List-by-Occupational-Series\n",
    "LIBSERIES = 1410\n",
    "resp = requests.get(\"https://data.usajobs.gov/api/jobs\", params = {'series': LIBSERIES})\n",
    "#print(resp.json()['TotalJobs'])\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.whitehouse.gov/sites/default/files/disclosures/whitehouse-waves-2012.csv_.zip to /tmp/whvisitors/whitehouse-waves-2012.csv_.zip\n",
      "Unzipping /tmp/whvisitors/whitehouse-waves-2012.csv_.zip to /tmp/whvisitors\n"
     ]
    },
    {
     "ename": "ReadError",
     "evalue": "/tmp/whvisitors/whitehouse-waves-2012.csv_.zip is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d0ecddf006bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# unzip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unzipping\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCAL_DATADIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0munpack_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCAL_DATADIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# the file was zipped on a Mac, yet still uses Windows encoding...mkaaay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36munpack_archive\u001b[0;34m(filename, extract_dir, format)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UNPACK_FORMATS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_UNPACK_FORMATS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_unpack_zipfile\u001b[0;34m(filename, extract_dir)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a zip file\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0mzip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReadError\u001b[0m: /tmp/whvisitors/whitehouse-waves-2012.csv_.zip is not a zip file"
     ]
    }
   ],
   "source": [
    "# Total number of visitors to the White House in 2012\n",
    "# landing page:\n",
    "# https://www.whitehouse.gov/briefing-room/disclosures/visitor-records\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "from shutil import unpack_archive\n",
    "LOCAL_DATADIR = \"/tmp/whvisitors\"\n",
    "url = 'https://www.whitehouse.gov/sites/default/files/disclosures/whitehouse-waves-2012.csv_.zip'\n",
    "zname = os.path.join(LOCAL_DATADIR, os.path.basename(url))\n",
    "cname = os.path.join(LOCAL_DATADIR, 'WhiteHouse-WAVES-2012.csv')\n",
    "os.makedirs(LOCAL_DATADIR, exist_ok = True)\n",
    "\n",
    "# Download the zip\n",
    "if not os.path.exists(zname):\n",
    "    print(\"Downloading\", url, 'to', zname)\n",
    "    z = requests.get(url).content\n",
    "    with open(zname, 'wb') as f:\n",
    "        f.write(z)\n",
    "\n",
    "# unzip it\n",
    "print(\"Unzipping\", zname, 'to', LOCAL_DATADIR)\n",
    "unpack_archive(zname, LOCAL_DATADIR)\n",
    "# the file was zipped on a Mac, yet still uses Windows encoding...mkaaay\n",
    "rows = list(csv.DictReader(open(cname, encoding = 'ISO-8859-1')))\n",
    "print(len(rows))\n",
    "# 934872"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Florida's lists of executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of inmates executed by Florida since 1976\n",
    "import requests\n",
    "from lxml import html\n",
    "url = \"http://www.dc.state.fl.us/oth/deathrow/execlist.html\"\n",
    "\n",
    "doc = html.fromstring(requests.get(url).text)\n",
    "tables = doc.cssselect('table.dcCSStableLight')\n",
    "rows = tables[0].cssselect('tr')\n",
    "# the first row is just the header row\n",
    "print(len(rows) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days until Texas's next scheduled execution\n",
    "from datetime import datetime\n",
    "from lxml import html\n",
    "import pytz\n",
    "import requests\n",
    "url = \"http://www.tdcj.state.tx.us/death_row/dr_scheduled_executions.html\"\n",
    "# fetch and parse the page\n",
    "doc = html.fromstring(requests.get(url).text)\n",
    "# Get our time in central texas time; http://stackoverflow.com/a/22109768/160863\n",
    "texas_time = pytz.timezone(\"US/Central\")\n",
    "today = texas_time.localize(datetime(*datetime.now().timetuple()[0:3])) # whatever, too lazy to look up the idiom\n",
    "for row in doc.xpath('//table/tr')[1:]:\n",
    "    # Even though this table is sorted in reverse-chronological order,\n",
    "    #  sometimes the executions happen more quickly than the updates to the\n",
    "    #  webpage, can't assume the first row is always the upcoming execution\n",
    "    #\n",
    "    # Each row looks like:\n",
    "    # | 08/12/2015 |  Info | Lopez | Daniel | 999555 | 09/15/1987 | H | 03/16/2010 | Nueces |\n",
    "    col = row.cssselect('td')[0]\n",
    "    exdate = datetime.strptime(col.text_content(), '%m/%d/%Y')\n",
    "    exdate = texas_time.localize(exdate)\n",
    "    if (exdate >= today):\n",
    "        print((exdate - today).days, \"days\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
